{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/dropped_columns_and_weather.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are manipulations of the DateTime column provided with the data, these additional features will hopefully help a model find patterns to help predict future demand at certain times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['DateTime'].dt.year\n",
    "df['quarter'] = df['DateTime'].dt.quarter\n",
    "df['month'] = df['DateTime'].dt.month\n",
    "df['day_of_year'] = df['DateTime'].dt.day_of_year\n",
    "df['day_of_month'] = df['DateTime'].dt.day\n",
    "df['day_of_week'] = df['DateTime'].dt.dayofweek\n",
    "df['hour'] = df['DateTime'].dt.hour\n",
    "df['minute'] = df['DateTime'].dt.minute\n",
    "df['time'] = df['DateTime'].dt.strftime('%H:%M')\n",
    "df['minute_of_day'] = df['hour'] * 60 + df['minute']\n",
    "\n",
    "\n",
    "df['DateTime'] = df['DateTime'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A feature of the sum of the demand for previous lengths of times is added,\n",
    "originally I had used a lag but as the intervals between readings changed in the last few months, lags represented different amounts of time.\n",
    "\n",
    "It is closed 'left' so that the time at the reading isn't included in the previous amount of time for the sum as to not leak any data into the training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.set_index('DateTime', inplace=True)\n",
    "\n",
    "\n",
    "df['sum_3min'] = df['demand'].rolling('3min', closed='left').sum()\n",
    "df['sum_5min'] = df['demand'].rolling('5min', closed='left').sum()\n",
    "df['sum_10min'] = df['demand'].rolling('10min', closed='left').sum()\n",
    "df['sum_15min'] = df['demand'].rolling('15min', closed='left').sum()\n",
    "df['sum_20min'] = df['demand'].rolling('20min', closed='left').sum()\n",
    "df['sum_30min'] = df['demand'].rolling('30min', closed='left').sum()\n",
    "df['sum_45min'] = df['demand'].rolling('45min', closed='left').sum()\n",
    "df['sum_1h'] = df['demand'].rolling('1h', closed='left').sum()\n",
    "df['sum_24h'] = df['demand'].rolling('24h', closed='left').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is more rolling statistics (means, stds, mins, max) which might help the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['rolling_mean_30min'] = df['demand'].rolling('30min', closed='left').mean()\n",
    "df['rolling_std_30min'] = df['demand'].rolling('30min', closed='left').std()\n",
    "\n",
    "df['rolling_mean_1h'] = df['demand'].rolling('1h', closed='left').mean()\n",
    "df['rolling_std_1h'] = df['demand'].rolling('1h', closed='left').std()\n",
    "\n",
    "df['rolling_mean_24h'] = df['demand'].rolling('24h', closed='left').mean()\n",
    "df['rolling_std_24h'] = df['demand'].rolling('24h', closed='left').std()\n",
    "\n",
    "df['rolling_min_24h'] = df['demand'].rolling('24h', closed='left').min()\n",
    "df['rolling_max_24h'] = df['demand'].rolling('24h', closed='left').max()\n",
    "\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('../data/fe_temp_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyclic times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous times added to the data donâ€™t capture the cyclical nature of these periods (i.e., after December (12) is January (1)). So, we use sine and cosine transformations to encode time features like month, day of the year, hour etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['quarter_sin'] = np.sin(2 * np.pi * df['quarter'] / 4)\n",
    "df['quarter_cos'] = np.cos(2 * np.pi * df['quarter'] / 4)\n",
    "\n",
    "\n",
    "df['day_of_month_sin'] = np.sin(2 * np.pi * df['day_of_month'] / 31)\n",
    "df['day_of_month_cos'] = np.cos(2 * np.pi * df['day_of_month'] / 31)\n",
    "\n",
    "\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "\n",
    "df['minute_of_day_sin'] = np.sin(2 * np.pi * df['minute'] / 60)\n",
    "df['minute_of_day_cos'] = np.cos(2 * np.pi * df['minute'] / 60)\n",
    "\n",
    "df['minute_sin'] = np.sin(2 * np.pi * df['minute_of_day'] / 1440)\n",
    "df['minute_cos'] = np.cos(2 * np.pi * df['minute_of_day'] / 1440)\n",
    "\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "\n",
    "df['day_of_year_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
    "df['day_of_year_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
    "\n",
    "\n",
    "df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "\n",
    "\n",
    "df.drop(columns=['hour', 'minute', 'day_of_week', 'month','minute_of_day','quarter','day_of_year','day_of_month'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('../data/fe_temp_cyclic_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the autocorrelation function for the demand shows that the demand is correlated both with the previous close by times, but there is also a little raise in betwwen 80 and 100, (96 would most normally represent a day as it would be 96 x 15minute intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(df.iloc[:-1].demand, lags=150)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
