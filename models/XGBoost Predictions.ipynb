{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally I was using ARIMA which was producing excellent results, however this was before I extended the dataset to include the varying demand collection frequency which I thought would be easy to migrate to. I struggled to use it for the final prediction and therefor resorted to XGBoost which performed more poorly on my predictions in the first half of the dataset.\n",
    "\n",
    "XGBoost has an edge in capturing non-linear patterns that traditional models like ARIMA might struggle to, while ARIMA work mostly with lagged versions of the target variable and seasonal adjustments, although this produced better results for me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from XGBoost_model_testing import model_testing_xgboost\n",
    "from plot_predictions import plot_predictions\n",
    "from rmses import rmse_evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cyclic = pd.read_pickle('../data/fe_temp_cyclic_data.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test dates are chosen due to varying nature curves they produce, and after the increased frequency of readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dates = [\n",
    "        '2023-10-28 09:33',\n",
    "        '2023-10-28 13:09',\n",
    "        '2023-11-02 06:27',\n",
    "        '2023-11-02 09:48'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cyclic_features = ['tempmax', 'tempmin', 'temp', 'precip',\n",
    "       'snow', 'snowdepth', 'windspeedmean', 'solarenergy', 'year',\n",
    "       'sum_3min', 'sum_5min', 'sum_10min', 'sum_15min', 'sum_20min',\n",
    "       'sum_30min', 'sum_45min', 'sum_1h', 'sum_24h', 'rolling_mean_30min',\n",
    "       'rolling_std_30min', 'rolling_mean_1h', 'rolling_std_1h',\n",
    "       'rolling_mean_24h', 'rolling_std_24h', 'rolling_min_24h',\n",
    "       'rolling_max_24h', 'quarter_sin', 'quarter_cos', 'day_of_month_sin',\n",
    "       'day_of_month_cos', 'hour_sin', 'hour_cos', 'minute_of_day_sin',\n",
    "       'minute_of_day_cos', 'minute_sin', 'minute_cos', 'month_sin',\n",
    "       'month_cos', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week_sin',\n",
    "       'day_of_week_cos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_predictions = model_testing_xgboost(df_cyclic,test_dates,df_cyclic_features)\n",
    "print(rmse_evaluator(df_with_predictions,test_dates,mini = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(df_with_predictions,test_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to broadly work, but struggles on the datapoints close to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will try some different data starting points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cyclic_after_2022 = df_cyclic[(df_cyclic.DateTime > '2022')].copy()\n",
    "df_cyclic_after_2022 = df_cyclic_after_2022.reset_index(drop = 'index')\n",
    "\n",
    "df_cyclic_after_2023 = df_cyclic[(df_cyclic.DateTime > '2023')].copy()\n",
    "df_cyclic_after_2023 = df_cyclic_after_2023.reset_index(drop = 'index')\n",
    "\n",
    "df_cyclic_after_2023_09 = df_cyclic[(df_cyclic.DateTime > '2023-09')].copy()\n",
    "df_cyclic_after_2023_09 = df_cyclic_after_2023_09.reset_index(drop = 'index')\n",
    "\n",
    "dfs = [df_cyclic,df_cyclic_after_2022,df_cyclic_after_2023,df_cyclic_after_2023_09 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the hyperparamaters found with Optuna and randomised search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    df_with_predictions = model_testing_xgboost(df,test_dates,df_cyclic_features, max_depth= 3,learning_rate=0.07,\n",
    "                                                n_estimators = 700, gamma = 0.25,subsample = 0.75)\n",
    "    print(rmse_evaluator(df_with_predictions,test_dates,mini = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    df = df.copy()\n",
    "    df.demand = np.log(df.demand)\n",
    "    df_with_predictions = model_testing_xgboost(df,test_dates,df_cyclic_features, max_depth= 3,learning_rate=0.07,\n",
    "                                                n_estimators = 700, gamma = 0.25,subsample = 0.75)\n",
    "    df_with_predictions['demand'] = df_with_predictions['demand'].apply(lambda x: np.exp(x) if pd.notna(x) else x)\n",
    "    df_with_predictions['predictions'] = df_with_predictions['predictions'].apply(lambda x: np.exp(x) if pd.notna(x) else x)\n",
    "\n",
    "    print(rmse_evaluator(df_with_predictions,test_dates,mini = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best result we have seen is actually with the shortest time frame, and with logging the demand, so we will try some predictions restricting the time frame into the final year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    df = df_cyclic.copy()\n",
    "    month = 3 + i\n",
    "    \n",
    "    df = df[(df.DateTime > '2023-0{}'.format(month))]\n",
    "    df.reset_index()\n",
    "    df.demand = np.log(df.demand)\n",
    "    df_with_predictions = model_testing_xgboost(df,test_dates,df_cyclic_features, max_depth= 3,learning_rate=0.07,\n",
    "                                                n_estimators = 700, gamma = 0.25,subsample = 0.75)\n",
    "    df_with_predictions['demand'] = df_with_predictions['demand'].apply(lambda x: np.exp(x) if pd.notna(x) else x)\n",
    "    df_with_predictions['predictions'] = df_with_predictions['predictions'].apply(lambda x: np.exp(x) if pd.notna(x) else x)\n",
    "\n",
    "    print(\"month\",month)\n",
    "    print(rmse_evaluator(df_with_predictions,test_dates,mini = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_cyclic.copy()\n",
    "df = df[(df.DateTime > '2023-08')]\n",
    "df.reset_index()\n",
    "df.demand = np.log(df.demand)\n",
    "df_with_predictions = model_testing_xgboost(df,test_dates,df_cyclic_features, max_depth= 3,learning_rate=0.07,\n",
    "                                            n_estimators = 700, gamma = 0.25,subsample = 0.75)\n",
    "df_with_predictions['demand'] = df_with_predictions['demand'].apply(lambda x: np.exp(x) if pd.notna(x) else x)\n",
    "df_with_predictions['predictions'] = df_with_predictions['predictions'].apply(lambda x: np.exp(x) if pd.notna(x) else x)\n",
    "rmse_evaluator(df_with_predictions,test_dates,mini = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_cyclic[(df_cyclic.DateTime > '2023-08')].copy()\n",
    "predicted_df = df_final.copy()\n",
    "predicted_df['predictions'] = None\n",
    "trainsize = len(predicted_df) - 1\n",
    "non_numeric_columns = df_final.select_dtypes(include=['object']).columns\n",
    "\n",
    "df_final = df_final.drop(columns=non_numeric_columns)\n",
    "df_train = df_final.iloc[:trainsize]\n",
    "\n",
    "X_train = df_train[df_cyclic_features]\n",
    "y_train = df_train['demand']\n",
    "xgb_model = XGBRegressor(n_estimators=700, learning_rate=0.07, max_depth=3,subsample =  0.75,gamma = 0.25)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "X_test = df_final.iloc[[trainsize]][df_cyclic_features]\n",
    "\n",
    "xgb_model.predict(X_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0.05571267]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With more time I would've explored more cleaning of the data, as there seemed to be some fishy demand reporting,\n",
    "I would've attempted reducing the number of variables, as many would overlap (through PCA) or just provide unhelpful noise which would surely increase accuracy\n",
    "\n",
    "The hyperparamater searches were also not explicitly on the data we used for our final predictions, so could be better optimised, as with the model choice"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
